{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MobileNetV2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPbP9EEt8BKJ72sjNCoXSGG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh2236945/pytorch_classification/blob/master/models/MobileNetV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyHmF6vd3wIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMYld4C_3zI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LambdaLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "    \n",
        "class Bottleneck(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, t, stride):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        \n",
        "        self.stride = stride\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        \n",
        "        self.features = nn.Sequential(OrderedDict([\n",
        "            ('pconv1', nn.Conv2d(in_channels,\n",
        "                                in_channels*t,\n",
        "                                kernel_size=1,\n",
        "                                stride=1,\n",
        "                                padding=0,\n",
        "                                bias=False)),\n",
        "            ('bn1', nn.BatchNorm2d(in_channels*t)),\n",
        "            ('act1', nn.ReLU6()),\n",
        "            ('dconv', nn.Conv2d(in_channels*t,\n",
        "                                in_channels*t,\n",
        "                                kernel_size=3,\n",
        "                                groups=in_channels*t,\n",
        "                                stride=stride,\n",
        "                                padding=1,\n",
        "                                bias=False)),\n",
        "            ('bn2', nn.BatchNorm2d(in_channels*t)),\n",
        "            ('act2', nn.ReLU6()),\n",
        "            ('pconv3', nn.Conv2d(in_channels*t,\n",
        "                                out_channels,\n",
        "                                kernel_size=1,\n",
        "                                stride=1,\n",
        "                                padding=0,\n",
        "                                bias=False)),\n",
        "            ('bn3', nn.BatchNorm2d(out_channels))\n",
        "        ]))\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        if self.stride == 1 and self.in_channels == self.out_channels:\n",
        "            out += x \n",
        "        return out\n",
        "\n",
        "class MobileNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, block_type, bottleneck_settings, width_multiplier, num_classes):\n",
        "        super(MobileNet, self).__init__()\n",
        "        \n",
        "        self.num_classes = num_classes\n",
        "        self.b_s = bottleneck_settings\n",
        "        self.b_s['c'] = [int(elt * width_multiplier) for elt in self.b_s['c']]\n",
        "        self.in_channels = int(32 * width_multiplier)\n",
        "        self.out_channels = int(1280 * width_multiplier)\n",
        "        \n",
        "        # Feature\n",
        "        self.conv0 = nn.Sequential(OrderedDict([\n",
        "            ('conv0', nn.Conv2d(3, self.in_channels, 1, stride=2, bias=False)),\n",
        "            ('bn0', nn.BatchNorm2d(self.in_channels)),\n",
        "            ('act0', nn.ReLU6()) \n",
        "        ]))\n",
        "        self.bottleneck1 = self.__build_layer(block_type,\n",
        "                                              self.in_channels, \n",
        "                                              self.b_s['c'][0], \n",
        "                                              self.b_s['t'][0],\n",
        "                                              self.b_s['s'][0],\n",
        "                                              self.b_s['n'][0])\n",
        "        self.bottleneck2 = self.__build_layer(block_type, \n",
        "                                              self.b_s['c'][0],\n",
        "                                              self.b_s['c'][1], \n",
        "                                              self.b_s['t'][1],\n",
        "                                              self.b_s['s'][1],\n",
        "                                              self.b_s['n'][1])\n",
        "        self.bottleneck3 = self.__build_layer(block_type,\n",
        "                                              self.b_s['c'][1],\n",
        "                                              self.b_s['c'][2],\n",
        "                                              self.b_s['t'][2],\n",
        "                                              self.b_s['s'][2],\n",
        "                                              self.b_s['n'][2])\n",
        "        self.bottleneck4 = self.__build_layer(block_type,\n",
        "                                              self.b_s['c'][2],\n",
        "                                              self.b_s['c'][3],\n",
        "                                              self.b_s['t'][3],\n",
        "                                              self.b_s['s'][3],\n",
        "                                              self.b_s['n'][3])\n",
        "        self.bottleneck5 = self.__build_layer(block_type,\n",
        "                                              self.b_s['c'][3],\n",
        "                                              self.b_s['c'][4],\n",
        "                                              self.b_s['t'][4],\n",
        "                                              self.b_s['s'][4],\n",
        "                                              self.b_s['n'][4])\n",
        "        self.bottleneck6 = self.__build_layer(block_type,\n",
        "                                              self.b_s['c'][4],\n",
        "                                              self.b_s['c'][5],\n",
        "                                              self.b_s['t'][5],\n",
        "                                              self.b_s['s'][5],\n",
        "                                              self.b_s['n'][5])\n",
        "        self.bottleneck7 = self.__build_layer(block_type,\n",
        "                                              self.b_s['c'][5],\n",
        "                                              self.b_s['c'][6],\n",
        "                                              self.b_s['t'][6],\n",
        "                                              self.b_s['s'][6],\n",
        "                                              self.b_s['n'][6])\n",
        "        # Classifier\n",
        "        self.conv8 = nn.Sequential(OrderedDict([\n",
        "            ('conv8', nn.Conv2d(self.b_s['c'][6], self.out_channels, 1, bias=False)),\n",
        "            ('bn8', nn.BatchNorm2d(self.out_channels)),\n",
        "            ('act8', nn.ReLU6()) \n",
        "        ]))\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.conv9 = nn.Conv2d(self.out_channels, num_classes, 1)\n",
        "    \n",
        "    def __build_layer(self, block_type, in_channels, out_channels, t, s, n):\n",
        "        layers = []\n",
        "        tmp_channels = in_channels\n",
        "        for i in range(n):\n",
        "            if i == 0:\n",
        "                layers.append(block_type(tmp_channels, out_channels, t, s))\n",
        "            else:\n",
        "                layers.append(block_type(tmp_channels, out_channels, t, 1))\n",
        "            tmp_channels = out_channels\n",
        "        return nn.Sequential(*layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.conv0(x)\n",
        "        out = self.bottleneck1(out)\n",
        "        out = self.bottleneck2(out)\n",
        "        out = self.bottleneck3(out)\n",
        "        out = self.bottleneck4(out)\n",
        "        out = self.bottleneck5(out)\n",
        "        out = self.bottleneck6(out)\n",
        "        out = self.bottleneck7(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = self.conv9(out)\n",
        "        out = out.view(-1, self.num_classes)\n",
        "        return out\n",
        "\n",
        "def MobileNetV2():\n",
        "    bottleneck_settings = {\n",
        "                'c': [16, 24, 32, 64, 96, 160, 320],\n",
        "                't': [1, 6, 6, 6, 6, 6, 6],\n",
        "                's': [1, 2, 2, 2, 1, 2, 1],\n",
        "                'n': [1, 2, 3, 4, 3, 3, 1]\n",
        "            }\n",
        "    \n",
        "    return MobileNet(block_type=Bottleneck,\n",
        "                     bottleneck_settings=bottleneck_settings,\n",
        "                     width_multiplier=.5,\n",
        "                     num_classes=1000)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNaDndFy3-ae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7cf8d92-2889-413b-86e7-5f59d30ce54b"
      },
      "source": [
        "model = MobileNetV2()\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "summary(model, (3, 96, 96))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 48, 48]              48\n",
            "       BatchNorm2d-2           [-1, 16, 48, 48]              32\n",
            "             ReLU6-3           [-1, 16, 48, 48]               0\n",
            "            Conv2d-4           [-1, 16, 48, 48]             256\n",
            "       BatchNorm2d-5           [-1, 16, 48, 48]              32\n",
            "             ReLU6-6           [-1, 16, 48, 48]               0\n",
            "            Conv2d-7           [-1, 16, 48, 48]             144\n",
            "       BatchNorm2d-8           [-1, 16, 48, 48]              32\n",
            "             ReLU6-9           [-1, 16, 48, 48]               0\n",
            "           Conv2d-10            [-1, 8, 48, 48]             128\n",
            "      BatchNorm2d-11            [-1, 8, 48, 48]              16\n",
            "       Bottleneck-12            [-1, 8, 48, 48]               0\n",
            "           Conv2d-13           [-1, 48, 48, 48]             384\n",
            "      BatchNorm2d-14           [-1, 48, 48, 48]              96\n",
            "            ReLU6-15           [-1, 48, 48, 48]               0\n",
            "           Conv2d-16           [-1, 48, 24, 24]             432\n",
            "      BatchNorm2d-17           [-1, 48, 24, 24]              96\n",
            "            ReLU6-18           [-1, 48, 24, 24]               0\n",
            "           Conv2d-19           [-1, 12, 24, 24]             576\n",
            "      BatchNorm2d-20           [-1, 12, 24, 24]              24\n",
            "       Bottleneck-21           [-1, 12, 24, 24]               0\n",
            "           Conv2d-22           [-1, 72, 24, 24]             864\n",
            "      BatchNorm2d-23           [-1, 72, 24, 24]             144\n",
            "            ReLU6-24           [-1, 72, 24, 24]               0\n",
            "           Conv2d-25           [-1, 72, 24, 24]             648\n",
            "      BatchNorm2d-26           [-1, 72, 24, 24]             144\n",
            "            ReLU6-27           [-1, 72, 24, 24]               0\n",
            "           Conv2d-28           [-1, 12, 24, 24]             864\n",
            "      BatchNorm2d-29           [-1, 12, 24, 24]              24\n",
            "       Bottleneck-30           [-1, 12, 24, 24]               0\n",
            "           Conv2d-31           [-1, 72, 24, 24]             864\n",
            "      BatchNorm2d-32           [-1, 72, 24, 24]             144\n",
            "            ReLU6-33           [-1, 72, 24, 24]               0\n",
            "           Conv2d-34           [-1, 72, 12, 12]             648\n",
            "      BatchNorm2d-35           [-1, 72, 12, 12]             144\n",
            "            ReLU6-36           [-1, 72, 12, 12]               0\n",
            "           Conv2d-37           [-1, 16, 12, 12]           1,152\n",
            "      BatchNorm2d-38           [-1, 16, 12, 12]              32\n",
            "       Bottleneck-39           [-1, 16, 12, 12]               0\n",
            "           Conv2d-40           [-1, 96, 12, 12]           1,536\n",
            "      BatchNorm2d-41           [-1, 96, 12, 12]             192\n",
            "            ReLU6-42           [-1, 96, 12, 12]               0\n",
            "           Conv2d-43           [-1, 96, 12, 12]             864\n",
            "      BatchNorm2d-44           [-1, 96, 12, 12]             192\n",
            "            ReLU6-45           [-1, 96, 12, 12]               0\n",
            "           Conv2d-46           [-1, 16, 12, 12]           1,536\n",
            "      BatchNorm2d-47           [-1, 16, 12, 12]              32\n",
            "       Bottleneck-48           [-1, 16, 12, 12]               0\n",
            "           Conv2d-49           [-1, 96, 12, 12]           1,536\n",
            "      BatchNorm2d-50           [-1, 96, 12, 12]             192\n",
            "            ReLU6-51           [-1, 96, 12, 12]               0\n",
            "           Conv2d-52           [-1, 96, 12, 12]             864\n",
            "      BatchNorm2d-53           [-1, 96, 12, 12]             192\n",
            "            ReLU6-54           [-1, 96, 12, 12]               0\n",
            "           Conv2d-55           [-1, 16, 12, 12]           1,536\n",
            "      BatchNorm2d-56           [-1, 16, 12, 12]              32\n",
            "       Bottleneck-57           [-1, 16, 12, 12]               0\n",
            "           Conv2d-58           [-1, 96, 12, 12]           1,536\n",
            "      BatchNorm2d-59           [-1, 96, 12, 12]             192\n",
            "            ReLU6-60           [-1, 96, 12, 12]               0\n",
            "           Conv2d-61             [-1, 96, 6, 6]             864\n",
            "      BatchNorm2d-62             [-1, 96, 6, 6]             192\n",
            "            ReLU6-63             [-1, 96, 6, 6]               0\n",
            "           Conv2d-64             [-1, 32, 6, 6]           3,072\n",
            "      BatchNorm2d-65             [-1, 32, 6, 6]              64\n",
            "       Bottleneck-66             [-1, 32, 6, 6]               0\n",
            "           Conv2d-67            [-1, 192, 6, 6]           6,144\n",
            "      BatchNorm2d-68            [-1, 192, 6, 6]             384\n",
            "            ReLU6-69            [-1, 192, 6, 6]               0\n",
            "           Conv2d-70            [-1, 192, 6, 6]           1,728\n",
            "      BatchNorm2d-71            [-1, 192, 6, 6]             384\n",
            "            ReLU6-72            [-1, 192, 6, 6]               0\n",
            "           Conv2d-73             [-1, 32, 6, 6]           6,144\n",
            "      BatchNorm2d-74             [-1, 32, 6, 6]              64\n",
            "       Bottleneck-75             [-1, 32, 6, 6]               0\n",
            "           Conv2d-76            [-1, 192, 6, 6]           6,144\n",
            "      BatchNorm2d-77            [-1, 192, 6, 6]             384\n",
            "            ReLU6-78            [-1, 192, 6, 6]               0\n",
            "           Conv2d-79            [-1, 192, 6, 6]           1,728\n",
            "      BatchNorm2d-80            [-1, 192, 6, 6]             384\n",
            "            ReLU6-81            [-1, 192, 6, 6]               0\n",
            "           Conv2d-82             [-1, 32, 6, 6]           6,144\n",
            "      BatchNorm2d-83             [-1, 32, 6, 6]              64\n",
            "       Bottleneck-84             [-1, 32, 6, 6]               0\n",
            "           Conv2d-85            [-1, 192, 6, 6]           6,144\n",
            "      BatchNorm2d-86            [-1, 192, 6, 6]             384\n",
            "            ReLU6-87            [-1, 192, 6, 6]               0\n",
            "           Conv2d-88            [-1, 192, 6, 6]           1,728\n",
            "      BatchNorm2d-89            [-1, 192, 6, 6]             384\n",
            "            ReLU6-90            [-1, 192, 6, 6]               0\n",
            "           Conv2d-91             [-1, 32, 6, 6]           6,144\n",
            "      BatchNorm2d-92             [-1, 32, 6, 6]              64\n",
            "       Bottleneck-93             [-1, 32, 6, 6]               0\n",
            "           Conv2d-94            [-1, 192, 6, 6]           6,144\n",
            "      BatchNorm2d-95            [-1, 192, 6, 6]             384\n",
            "            ReLU6-96            [-1, 192, 6, 6]               0\n",
            "           Conv2d-97            [-1, 192, 6, 6]           1,728\n",
            "      BatchNorm2d-98            [-1, 192, 6, 6]             384\n",
            "            ReLU6-99            [-1, 192, 6, 6]               0\n",
            "          Conv2d-100             [-1, 48, 6, 6]           9,216\n",
            "     BatchNorm2d-101             [-1, 48, 6, 6]              96\n",
            "      Bottleneck-102             [-1, 48, 6, 6]               0\n",
            "          Conv2d-103            [-1, 288, 6, 6]          13,824\n",
            "     BatchNorm2d-104            [-1, 288, 6, 6]             576\n",
            "           ReLU6-105            [-1, 288, 6, 6]               0\n",
            "          Conv2d-106            [-1, 288, 6, 6]           2,592\n",
            "     BatchNorm2d-107            [-1, 288, 6, 6]             576\n",
            "           ReLU6-108            [-1, 288, 6, 6]               0\n",
            "          Conv2d-109             [-1, 48, 6, 6]          13,824\n",
            "     BatchNorm2d-110             [-1, 48, 6, 6]              96\n",
            "      Bottleneck-111             [-1, 48, 6, 6]               0\n",
            "          Conv2d-112            [-1, 288, 6, 6]          13,824\n",
            "     BatchNorm2d-113            [-1, 288, 6, 6]             576\n",
            "           ReLU6-114            [-1, 288, 6, 6]               0\n",
            "          Conv2d-115            [-1, 288, 6, 6]           2,592\n",
            "     BatchNorm2d-116            [-1, 288, 6, 6]             576\n",
            "           ReLU6-117            [-1, 288, 6, 6]               0\n",
            "          Conv2d-118             [-1, 48, 6, 6]          13,824\n",
            "     BatchNorm2d-119             [-1, 48, 6, 6]              96\n",
            "      Bottleneck-120             [-1, 48, 6, 6]               0\n",
            "          Conv2d-121            [-1, 288, 6, 6]          13,824\n",
            "     BatchNorm2d-122            [-1, 288, 6, 6]             576\n",
            "           ReLU6-123            [-1, 288, 6, 6]               0\n",
            "          Conv2d-124            [-1, 288, 3, 3]           2,592\n",
            "     BatchNorm2d-125            [-1, 288, 3, 3]             576\n",
            "           ReLU6-126            [-1, 288, 3, 3]               0\n",
            "          Conv2d-127             [-1, 80, 3, 3]          23,040\n",
            "     BatchNorm2d-128             [-1, 80, 3, 3]             160\n",
            "      Bottleneck-129             [-1, 80, 3, 3]               0\n",
            "          Conv2d-130            [-1, 480, 3, 3]          38,400\n",
            "     BatchNorm2d-131            [-1, 480, 3, 3]             960\n",
            "           ReLU6-132            [-1, 480, 3, 3]               0\n",
            "          Conv2d-133            [-1, 480, 3, 3]           4,320\n",
            "     BatchNorm2d-134            [-1, 480, 3, 3]             960\n",
            "           ReLU6-135            [-1, 480, 3, 3]               0\n",
            "          Conv2d-136             [-1, 80, 3, 3]          38,400\n",
            "     BatchNorm2d-137             [-1, 80, 3, 3]             160\n",
            "      Bottleneck-138             [-1, 80, 3, 3]               0\n",
            "          Conv2d-139            [-1, 480, 3, 3]          38,400\n",
            "     BatchNorm2d-140            [-1, 480, 3, 3]             960\n",
            "           ReLU6-141            [-1, 480, 3, 3]               0\n",
            "          Conv2d-142            [-1, 480, 3, 3]           4,320\n",
            "     BatchNorm2d-143            [-1, 480, 3, 3]             960\n",
            "           ReLU6-144            [-1, 480, 3, 3]               0\n",
            "          Conv2d-145             [-1, 80, 3, 3]          38,400\n",
            "     BatchNorm2d-146             [-1, 80, 3, 3]             160\n",
            "      Bottleneck-147             [-1, 80, 3, 3]               0\n",
            "          Conv2d-148            [-1, 480, 3, 3]          38,400\n",
            "     BatchNorm2d-149            [-1, 480, 3, 3]             960\n",
            "           ReLU6-150            [-1, 480, 3, 3]               0\n",
            "          Conv2d-151            [-1, 480, 3, 3]           4,320\n",
            "     BatchNorm2d-152            [-1, 480, 3, 3]             960\n",
            "           ReLU6-153            [-1, 480, 3, 3]               0\n",
            "          Conv2d-154            [-1, 160, 3, 3]          76,800\n",
            "     BatchNorm2d-155            [-1, 160, 3, 3]             320\n",
            "      Bottleneck-156            [-1, 160, 3, 3]               0\n",
            "          Conv2d-157            [-1, 640, 3, 3]         102,400\n",
            "     BatchNorm2d-158            [-1, 640, 3, 3]           1,280\n",
            "           ReLU6-159            [-1, 640, 3, 3]               0\n",
            "AdaptiveAvgPool2d-160            [-1, 640, 1, 1]               0\n",
            "          Conv2d-161           [-1, 1000, 1, 1]         641,000\n",
            "================================================================\n",
            "Total params: 1,221,672\n",
            "Trainable params: 1,221,672\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.11\n",
            "Forward/backward pass size (MB): 14.89\n",
            "Params size (MB): 4.66\n",
            "Estimated Total Size (MB): 19.66\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}