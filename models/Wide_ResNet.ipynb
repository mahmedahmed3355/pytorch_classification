{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wide_ResNet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnwOBxmZiwwxysb53BBttm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moh2236945/pytorch_classification/blob/master/models/Wide_ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXmakK0VwDwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "from torchvision import transforms, datasets\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader, random_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRzIHlYzv_Ja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "99fcac85-040e-476b-9513-77a1a9194bfa"
      },
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
        "        init.constant_(m.bias, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "class wide_basic(nn.Module):\n",
        "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
        "        super(wide_basic, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Wide_ResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
        "        super(Wide_ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
        "        n = (depth-4)/6\n",
        "        k = widen_factor\n",
        "\n",
        "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
        "        nStages = [16, 16*k, 32*k, 64*k]\n",
        "\n",
        "        self.conv1 = conv3x3(3,nStages[0])\n",
        "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
        "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
        "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
        "        self.linear = nn.Linear(nStages[3], num_classes)\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
        "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    net=Wide_ResNet(28, 10, 0.3, 10)\n",
        "    y = net(Variable(torch.randn(1,3,32,32)))\n",
        "\n",
        "    print(y.size())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Wide-Resnet 28x10\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZROpDfspkvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c88cdcb3-9051-4709-c21b-643bba8a6878"
      },
      "source": [
        "model = Wide_ResNet(28, 10, 0.3, 10)\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "summary(model, (3, 32, 32))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Wide-Resnet 28x10\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 16, 32, 32]             448\n",
            "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
            "            Conv2d-3          [-1, 160, 32, 32]          23,200\n",
            "           Dropout-4          [-1, 160, 32, 32]               0\n",
            "       BatchNorm2d-5          [-1, 160, 32, 32]             320\n",
            "            Conv2d-6          [-1, 160, 32, 32]         230,560\n",
            "            Conv2d-7          [-1, 160, 32, 32]           2,720\n",
            "        wide_basic-8          [-1, 160, 32, 32]               0\n",
            "       BatchNorm2d-9          [-1, 160, 32, 32]             320\n",
            "           Conv2d-10          [-1, 160, 32, 32]         230,560\n",
            "          Dropout-11          [-1, 160, 32, 32]               0\n",
            "      BatchNorm2d-12          [-1, 160, 32, 32]             320\n",
            "           Conv2d-13          [-1, 160, 32, 32]         230,560\n",
            "       wide_basic-14          [-1, 160, 32, 32]               0\n",
            "      BatchNorm2d-15          [-1, 160, 32, 32]             320\n",
            "           Conv2d-16          [-1, 160, 32, 32]         230,560\n",
            "          Dropout-17          [-1, 160, 32, 32]               0\n",
            "      BatchNorm2d-18          [-1, 160, 32, 32]             320\n",
            "           Conv2d-19          [-1, 160, 32, 32]         230,560\n",
            "       wide_basic-20          [-1, 160, 32, 32]               0\n",
            "      BatchNorm2d-21          [-1, 160, 32, 32]             320\n",
            "           Conv2d-22          [-1, 160, 32, 32]         230,560\n",
            "          Dropout-23          [-1, 160, 32, 32]               0\n",
            "      BatchNorm2d-24          [-1, 160, 32, 32]             320\n",
            "           Conv2d-25          [-1, 160, 32, 32]         230,560\n",
            "       wide_basic-26          [-1, 160, 32, 32]               0\n",
            "      BatchNorm2d-27          [-1, 160, 32, 32]             320\n",
            "           Conv2d-28          [-1, 320, 32, 32]         461,120\n",
            "          Dropout-29          [-1, 320, 32, 32]               0\n",
            "      BatchNorm2d-30          [-1, 320, 32, 32]             640\n",
            "           Conv2d-31          [-1, 320, 16, 16]         921,920\n",
            "           Conv2d-32          [-1, 320, 16, 16]          51,520\n",
            "       wide_basic-33          [-1, 320, 16, 16]               0\n",
            "      BatchNorm2d-34          [-1, 320, 16, 16]             640\n",
            "           Conv2d-35          [-1, 320, 16, 16]         921,920\n",
            "          Dropout-36          [-1, 320, 16, 16]               0\n",
            "      BatchNorm2d-37          [-1, 320, 16, 16]             640\n",
            "           Conv2d-38          [-1, 320, 16, 16]         921,920\n",
            "       wide_basic-39          [-1, 320, 16, 16]               0\n",
            "      BatchNorm2d-40          [-1, 320, 16, 16]             640\n",
            "           Conv2d-41          [-1, 320, 16, 16]         921,920\n",
            "          Dropout-42          [-1, 320, 16, 16]               0\n",
            "      BatchNorm2d-43          [-1, 320, 16, 16]             640\n",
            "           Conv2d-44          [-1, 320, 16, 16]         921,920\n",
            "       wide_basic-45          [-1, 320, 16, 16]               0\n",
            "      BatchNorm2d-46          [-1, 320, 16, 16]             640\n",
            "           Conv2d-47          [-1, 320, 16, 16]         921,920\n",
            "          Dropout-48          [-1, 320, 16, 16]               0\n",
            "      BatchNorm2d-49          [-1, 320, 16, 16]             640\n",
            "           Conv2d-50          [-1, 320, 16, 16]         921,920\n",
            "       wide_basic-51          [-1, 320, 16, 16]               0\n",
            "      BatchNorm2d-52          [-1, 320, 16, 16]             640\n",
            "           Conv2d-53          [-1, 640, 16, 16]       1,843,840\n",
            "          Dropout-54          [-1, 640, 16, 16]               0\n",
            "      BatchNorm2d-55          [-1, 640, 16, 16]           1,280\n",
            "           Conv2d-56            [-1, 640, 8, 8]       3,687,040\n",
            "           Conv2d-57            [-1, 640, 8, 8]         205,440\n",
            "       wide_basic-58            [-1, 640, 8, 8]               0\n",
            "      BatchNorm2d-59            [-1, 640, 8, 8]           1,280\n",
            "           Conv2d-60            [-1, 640, 8, 8]       3,687,040\n",
            "          Dropout-61            [-1, 640, 8, 8]               0\n",
            "      BatchNorm2d-62            [-1, 640, 8, 8]           1,280\n",
            "           Conv2d-63            [-1, 640, 8, 8]       3,687,040\n",
            "       wide_basic-64            [-1, 640, 8, 8]               0\n",
            "      BatchNorm2d-65            [-1, 640, 8, 8]           1,280\n",
            "           Conv2d-66            [-1, 640, 8, 8]       3,687,040\n",
            "          Dropout-67            [-1, 640, 8, 8]               0\n",
            "      BatchNorm2d-68            [-1, 640, 8, 8]           1,280\n",
            "           Conv2d-69            [-1, 640, 8, 8]       3,687,040\n",
            "       wide_basic-70            [-1, 640, 8, 8]               0\n",
            "      BatchNorm2d-71            [-1, 640, 8, 8]           1,280\n",
            "           Conv2d-72            [-1, 640, 8, 8]       3,687,040\n",
            "          Dropout-73            [-1, 640, 8, 8]               0\n",
            "      BatchNorm2d-74            [-1, 640, 8, 8]           1,280\n",
            "           Conv2d-75            [-1, 640, 8, 8]       3,687,040\n",
            "       wide_basic-76            [-1, 640, 8, 8]               0\n",
            "      BatchNorm2d-77            [-1, 640, 8, 8]           1,280\n",
            "           Linear-78                   [-1, 10]           6,410\n",
            "================================================================\n",
            "Total params: 36,489,290\n",
            "Trainable params: 36,489,290\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 63.38\n",
            "Params size (MB): 139.20\n",
            "Estimated Total Size (MB): 202.58\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}